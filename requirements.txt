# === CRITICAL: torch handling ===
# Do NOT include torch in requirements.txt when using the official PyTorch container
# The container has torch pre-installed with correct CUDA bindings
# Reinstalling via pip causes version/CUDA mismatches

# Core (no torch - use container's version)
transformers==4.36.2
datasets==2.16.1
accelerate==0.26.1

# Flash Attention: EXPLICITLY NOT USED
# Flash attention changes precision characteristics.
# For this study, we use standard SDPA without flash.

# RLHF-specific (reference only, not imported)
# trl==0.7.4  # We implement our own PPO
peft==0.7.1             # Optional: LoRA experiments

# Analysis & Plotting
numpy==1.26.3
pandas==2.1.4
matplotlib==3.8.2
seaborn==0.13.1
plotly==5.18.0          # Interactive plots for exploration

# Monitoring
tqdm==4.66.1
huggingface_hub>=0.20.0  # For huggingface-cli login

# NO WANDB - we use custom JSON reporting for full control
